{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffce0b0b",
   "metadata": {},
   "source": [
    "# MSS 462 Final Project\n",
    "\n",
    "Have you ever wanted to track what your cat is doing around your house during the day?\n",
    "\n",
    "Me too! \n",
    "\n",
    "This computer vision project takes an image and puts a bounding box around cats that are in the image. \n",
    "It is built with Resnet-50 as the basis, then additional fine-tuning is done using the \"feline-felid\" dataset from ImageNet. \n",
    "Since this is a transfer learning situation, I froze the resnet layers and just train the outputs\n",
    "\n",
    "The model is then exported as a tflite model, so that I can run it on a Raspberry Pi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a091db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image as PIL_Image\n",
    "from PIL import ImageDraw as PIL_Draw\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# all of the tensorflow stuff\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for bringing in the dataset\n",
    "from tkinter import Tk\n",
    "from tkinter import filedialog as fd\n",
    "from os import listdir, path\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee81ba8a",
   "metadata": {},
   "source": [
    "### Define the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38ad69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a model to just say whether a cat is in the image\n",
    "def cat_tagger():\n",
    "    inputs = tf.keras.Input(shape=(224,224,3))\n",
    "    \n",
    "    resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "        \n",
    "    x = resnet(inputs, training=False)\n",
    "    classifier = tf.keras.layers.MaxPool2D()(x)\n",
    "    classifier = tf.keras.layers.Flatten()(classifier) # flatten the whole thing\n",
    "    classifier = tf.keras.layers.Dense(1024, activation='relu')(classifier) # add a training layer\n",
    "    classifier = tf.keras.layers.Dense(1, activation='sigmoid')(classifier) # is it a cat?\n",
    "    \n",
    "    for layer in resnet.layers: # make the Resnet instance untrainable\n",
    "        layer.trainable = False \n",
    "\n",
    "    # return classifier\n",
    "    return Model(inputs=inputs, outputs=classifier)\n",
    "\n",
    "# model to set the bounding box on the cat\n",
    "def cat_boxer():\n",
    "    inputs = tf.keras.Input(shape=(224,224,3))\n",
    "    \n",
    "    resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "    for layer in resnet.layers: # make the Resnet instance untrainable\n",
    "        layer.trainable = False \n",
    "        \n",
    "    classifier = resnet(inputs, training=False)\n",
    "    classifier = tf.keras.layers.MaxPool2D()(classifier)\n",
    "    classifier = tf.keras.layers.Flatten()(classifier) # flatten the whole thing\n",
    "    classifier = tf.keras.layers.Dense(1024, activation='relu')(classifier) # add a training layer\n",
    "    classifier = tf.keras.layers.Dense(224*224, activation='sigmoid')(classifier) # cat bounding box\n",
    "    \n",
    "    return Model(inputs=inputs, outputs=classifier)\n",
    "\n",
    "# models\n",
    "def cat_tagger_basic():\n",
    "    inputs = tf.keras.Input((224,224,3))\n",
    "    x = tf.keras.layers.Conv2D(3,4,activation='relu')(inputs)\n",
    "    x = tf.keras.layers.AvgPool2D()(x)\n",
    "    x = tf.keras.layers.Conv2D(1,4,activation='relu')(x)\n",
    "    # x = tf.keras.layers.AvgPool2D()(x)\n",
    "    # x = tf.keras.layers.Conv2D(1,4,activation='relu')(x)\n",
    "    # x = tf.keras.layers.Conv2D(1,4,activation='relu')(x)\n",
    "    # x = tf.keras.layers.MaxPool2D()(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    return Model(inputs=inputs, outputs=x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b048b292",
   "metadata": {},
   "source": [
    "### Bring in the training data\n",
    "\n",
    "This is the feline dataset from ImageNet\n",
    "\n",
    "The bounding boxes are defined in PASCAL VOC XML files, so unfortunately we have to manually traverse the xml tree rather than just use xml_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ce3122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_bbox(filepath):\n",
    "\n",
    "    # if we don't have a bounding box for that file...\n",
    "    if not path.exists(filepath):\n",
    "        return None\n",
    "    \n",
    "    imagesize = (224,224)\n",
    "\n",
    "    tree = ET.parse(filepath)\n",
    "    root = tree.getroot() # root of the tree\n",
    "\n",
    "    scalex = imagesize[0]/float(root.find('size/width').text)\n",
    "    scaley = imagesize[1]/float(root.find('size/height').text)\n",
    "\n",
    "    for boxes in root.iter('object'): # for each subelement\n",
    "        # filename = root.find('filename').text # get the document name\n",
    "        ymin = float(boxes.find('bndbox/ymin').text)\n",
    "        ymax = float(boxes.find('bndbox/ymax').text)\n",
    "        xmin = float(boxes.find('bndbox/xmin').text)\n",
    "        xmax = float(boxes.find('bndbox/xmax').text)\n",
    "\n",
    "    ymin = int(ymin*scaley)\n",
    "    ymax = int(ymax*scaley)\n",
    "    xmin = int(xmin*scalex)\n",
    "    xmax = int(xmax*scalex)\n",
    "\n",
    "    bnd_im = np.zeros(imagesize)\n",
    "    bnd_im[xmin:xmax, ymin:ymax] = 1\n",
    "\n",
    "    # return bnd_im, [xmin,ymin,xmax,ymax]\n",
    "    return bnd_im"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c1e349",
   "metadata": {},
   "source": [
    "We'll be loading in a few datasets here. \n",
    "\n",
    "The first is all of the \"cat\" pictures from the imagenet dataset. After running it through the Keras pre-processing module, that will give us a Nx224x224x3 array. N is the number of images, and each image is a 224 pixel square in RGB format\n",
    "\n",
    "We also have a array of \"not cat\" pictures, that will be Mx224x224x3; M is the number of \"not-cat\" images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e112598f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this create root is a gross hack that I haven't figure out how to avoid\n",
    "# and don't care enough to spend time looking up\n",
    "\n",
    "# basedir -- cat_pics, cat_bbox, and notcat_pics should all be inside\n",
    "root = Tk()\n",
    "base_dir = fd.askdirectory(master=root)\n",
    "root.destroy()\n",
    "\n",
    "cat_dir = path.join(base_dir, 'cat_pics')\n",
    "notcat_dir = path.join(base_dir, 'notcat_pics')\n",
    "\n",
    "if not path.exists(cat_dir):\n",
    "    print('Not finding the right subdirectories!')\n",
    "    KeyboardInterrupt()\n",
    "\n",
    "cat_list = [file for file in listdir(cat_dir) if 'jpeg' in file.lower()]\n",
    "cats = np.ndarray((len(cat_list), 224, 224, 3)) # 3 for rgb, one for mask\n",
    "cat_i = 0\n",
    "for file in cat_list:\n",
    "    img = image.load_img(path.join(cat_dir,file), target_size=(224,224)) # load it in\n",
    "    ary = image.img_to_array(img)\n",
    "    cats[cat_i,:,:,0:3] = ary # insert the image\n",
    "    cat_i += 1\n",
    "\n",
    "notcat_rng = np.random.default_rng()\n",
    "notcat_list = [file for file in listdir(notcat_dir) if 'jpeg' in file.lower()]\n",
    "not_cat = np.ndarray((len(notcat_list),224,224,3)) # just use a np array\n",
    "notcat_i = 0\n",
    "for file in notcat_list:\n",
    "    img = image.load_img(path.join(notcat_dir,file), target_size=(224,224)) # load it in\n",
    "    ary = image.img_to_array(img)\n",
    "\n",
    "    not_cat[notcat_i,:,:,:] = ary # image\n",
    "    notcat_i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd158f4",
   "metadata": {},
   "source": [
    "Since the images seem to take up an inordinate amount of RAM (likely because of the size of the resnet layers) we're going to create a data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de55e625",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size = 32) -> None:\n",
    "        super().__init__()\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x)/float(self.batch_size)))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx+1)*self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx+1)*self.batch_size]\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee351e55",
   "metadata": {},
   "source": [
    "Let's pickle the entire dataset so that we can just reload it from a single file\n",
    "\n",
    "The original data creation normally takes about 7 minutes, so that will help speed things up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b168aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fn = 'cat.pkl'\n",
    "save_notcat_fn = 'not_cat.pkl'\n",
    "\n",
    "with open(path.join(base_dir, save_fn), 'wb') as fid:\n",
    "    pickle.dump(cats, fid)\n",
    "\n",
    "with open(path.join(base_dir,save_notcat_fn), 'wb') as fid:\n",
    "    pickle.dump(not_cat, fid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c3e34d",
   "metadata": {},
   "source": [
    "if we save it, we need to be able to open it too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9290177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cats\n",
    "root = Tk()\n",
    "open_fn = fd.askopenfilename(master=root, defaultextension='*.pkl')\n",
    "root.destroy()\n",
    "\n",
    "with open(open_fn, 'rb') as fid:\n",
    "    cats = pickle.load(fid)\n",
    "\n",
    "# not cats\n",
    "root = Tk()\n",
    "open_fn = fd.askopenfilename(master=root, defaultextension='*.pkl')\n",
    "root.destroy()\n",
    "\n",
    "with open(open_fn, 'rb') as fid:\n",
    "    not_cat = pickle.load(fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152df3a0",
   "metadata": {},
   "source": [
    "### instantiate the model and train\n",
    "\n",
    "first starting by tagging images with cats compared with images without cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93764139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels for if the image is a cat or not\n",
    "cat_notcat = np.concatenate([np.ones(cats.shape[0]),np.zeros(not_cat.shape[0])])\n",
    "\n",
    "images = np.concatenate([cats[:,:,:,:3],not_cat])\n",
    "\n",
    "train_im, test_im, train_lab, test_lab = train_test_split(images, cat_notcat, train_size=.8)\n",
    "\n",
    "train_gen = DataGenerator(train_im, train_lab, 32)\n",
    "test_gen = DataGenerator(test_im, test_lab, 32)\n",
    "\n",
    "mdl = cat_tagger()\n",
    "# mdl = cat_tagger_basic()\n",
    "mdl.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(), metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
    "# mdl.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=.1), loss=tf.keras.losses.BinaryCrossentropy(), metrics=[tf.keras.metrics.BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35030276",
   "metadata": {},
   "source": [
    "Now that the model has been initialized and compiled, we need to fit it. I am using 10 epochs, though that can obviously get changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c94edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger_history = mdl.fit(train_gen, verbose=True, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52b793d",
   "metadata": {},
   "source": [
    "To run the model on the raspberry pi, we need to convert the model into tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b1f624",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_fn = 'cat_tagger_model'\n",
    "\n",
    "mdl.save(path.join(base_dir,mdl_fn))\n",
    "\n",
    "# convert to tflite\n",
    "cat_tagger_tflite = tf.lite.TFLiteConverter.from_saved_model(path.join(base_dir,mdl_fn)).convert()\n",
    "with open(mdl_fn+'.tflite', 'wb') as fid:\n",
    "    fid.write(cat_tagger_tflite)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3201349c",
   "metadata": {},
   "source": [
    "And we need to be able to load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff0828e",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Tk()\n",
    "mdl_fn = fd.askdirectory(master=root)\n",
    "root.destroy()\n",
    "\n",
    "mdl = tf.keras.models.load_model(mdl_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cea5aa",
   "metadata": {},
   "source": [
    "Let's predict a random subset of the testing data, and see how it looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a730c6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_numbers = notcat_rng.choice(test_im.shape[0], 5)\n",
    "\n",
    "switch = ['Not a cat!','Cat!']\n",
    "\n",
    "for im_num in image_numbers:\n",
    "    print(switch[int(mdl.predict(np.expand_dims(test_im[im_num,:,:,:3], axis=0), verbose=0)[0,0])])\n",
    "    display(image.array_to_img(test_im[im_num,:,:,:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee52ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger_trainAcc = metrics.accuracy_score(test_lab.astype(float), mdl.predict(test_im,verbose=0)[0].ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd45a65",
   "metadata": {},
   "source": [
    "Now, to summarize the testing and training results:\n",
    "\n",
    "First, let's take a look at the training accuracy over the course of training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926c5839",
   "metadata": {},
   "source": [
    "### Training the bounding boxes\n",
    "\n",
    "This is a separate model setup. Instead of training on a single output (is the image a cat) we are going to training on an output \"mask\" that is a 1 inside of the bounding box and a 0 outside of it.\n",
    "\n",
    "This is a much smaller dataset than the previous one, since there are only a subset of the images that have been given bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f094d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basedir -- cat_pics, cat_bbox, and notcat_pics should all be inside\n",
    "root = Tk()\n",
    "base_dir = fd.askdirectory(master=root)\n",
    "root.destroy()\n",
    "\n",
    "cat_dir = path.join(base_dir, 'cat_pics')\n",
    "bbox_dir = path.join(base_dir, 'cat_bbox')\n",
    "notcat_dir = path.join(base_dir, 'notcat_pics')\n",
    "\n",
    "# get a list of the files that we will check\n",
    "filelist = [file for file in listdir(bbox_dir) if '.xml' in file]\n",
    "\n",
    "images = np.ndarray((len(filelist),224,224,3))\n",
    "masks = np.ndarray((len(filelist),224*224))\n",
    "# bboxes = np.ndarray((len(filelist),4))\n",
    "cat_i = 0\n",
    "for file in filelist:\n",
    "    temp_img = image.load_img(path.join(cat_dir, path.splitext(file)[0])+'.JPEG', target_size=(224,224))\n",
    "    images[cat_i,:,:,:] = image.img_to_array(temp_img)\n",
    "    # temp_mask, bboxes[cat_i,:] = parse_bbox(path.join(bbox_dir, file))\n",
    "    temp_mask = parse_bbox(path.join(bbox_dir, file))\n",
    "    masks[cat_i,:] = temp_mask.ravel()\n",
    "    cat_i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c86e22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now for the image segmentation portions\n",
    "train_im,test_im, train_masks,test_masks = train_test_split(images, masks, train_size=.8)\n",
    "train_gen = DataGenerator(train_im, train_masks, 64)\n",
    "\n",
    "mdl = cat_boxer()\n",
    "\n",
    "mdl.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(), metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
    "\n",
    "# fit the model\n",
    "boxer_history = mdl.fit(train_gen, verbose=True, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577514cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_rng = np.random.default_rng()\n",
    "\n",
    "image_numbers = im_rng.choice(len(test_im), 5)\n",
    "\n",
    "for im_num in image_numbers:\n",
    "    temp_img = image.array_to_img(test_im[im_num,:,:,:])\n",
    "    temp_draw = PIL_Draw.Draw(temp_img)\n",
    "    temp_draw.rectangle([(bboxes[im_num,0:2])(bboxes[im_num,2:4])], outline='black')\n",
    "    display(temp_draw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6241562e",
   "metadata": {},
   "source": [
    "Save the model as a tflite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfadb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fn = 'cat_boxer_model'\n",
    "\n",
    "mdl.save(path.join(base_dir, save_fn))\n",
    "\n",
    "# convert to tflite\n",
    "cat_tagger_tflite = tf.lite.TFLiteConverter.from_saved_model(path.join(base_dir,mdl_fn)).convert()\n",
    "with open(mdl_fn+'.tflite', 'wb') as fid:\n",
    "    fid.write(cat_tagger_tflite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95134247",
   "metadata": {},
   "source": [
    "### Summarizing the training and the results\n",
    "\n",
    "Starting with the cat tagger model, we'll look at the training metrics over epochs, and the testing accuracy for the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c138626f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(range(1,11), tagger_history.history['binary_accuracy'])\n",
    "# ax[1].plot(range(1,11), boxer_history.history['binary_accuracy'])\n",
    "\n",
    "ax.set_title('Training Accuracy')\n",
    "ax.set_xlabel('Training Epoch')\n",
    "ax.set_ylabel('Accuracy Percentage')\n",
    "# ax[1].set_title('Cat_Boxer Training Accuracy')\n",
    "\n",
    "for spine in ax.spines:\n",
    "    ax.spines[spine].set_visible(False)\n",
    "\n",
    "ax.set_ylim([0.85,1.01])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f5cc7d6",
   "metadata": {},
   "source": [
    "## Scratch space\n",
    "\n",
    "To delete tensors that are taking up too much memory etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3b5bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(train_gen)\n",
    "del(test_gen)\n",
    "\n",
    "del(test_im)\n",
    "del(test_lab)\n",
    "del(train_im)\n",
    "del(train_lab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('MSDS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Oct 13 2022, 21:23:06) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "e6f5ab44297089514ffa059ea0d83d6392bebfea7e191fb6b7f26c8412c9553b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
